{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 코드 순서\n",
    "- [1️⃣ Create deployment using 🦾 Bicep](#2)\n",
    "- [🧪 직접 HTTP를 호출하여 API 테스트](#requests)\n",
    "- [🔍 Load Balancing 결과 분석](#plot)\n",
    "\n",
    "### 사전 준비 사항\n",
    "- [Python 3.8 or later version](https://www.python.org/) installed\n",
    "- [Pandas Library](https://pandas.pydata.org/) and matplotlib installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Azure CLI](https://learn.microsoft.com/en-us/cli/azure/install-azure-cli) installed\n",
    "- [Sign in to Azure with Azure CLI](https://learn.microsoft.com/en-us/cli/azure/authenticate-azure-cli-interactively)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1️⃣ 🦾 Bicep을 사용하여 API Management의 Backend Pool을 등록합니다.\n",
    "\n",
    "이 단계에서는 [Bicep](https://learn.microsoft.com/en-us/azure/azure-resource-manager/bicep/overview?tabs=bicep)을 이용하여 Backend Pool을 등록합니다.\n",
    "backend-pool.bicep의 변수들을 입력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! az deployment group create --name backend-pool-deployment --resource-group {your-resource-grop}} --template-file \"backend-pool.bicep\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='requests'></a>\n",
    "### 🧪 직접 HTTP를 호출하여 API 테스트\n",
    "Request는 간단한 raw API request를 만들고 응답을 받아오는 Python용 HTTP 라이브러리입니다.\n",
    "\n",
    "HTTP 429 응답코드는 보지 못할 것입니다. API Management의 `retry` policy가 가용한 backend를 선택할 것이고, 가용한 backend가 없다면 HTTP 503이 리턴 될 것입니다.\n",
    "\n",
    "*Note: 아래 내용을 입력 한 후 실행하세요.\n",
    "1. apim_resource_gateway_url: API Gateway URL\n",
    "2. openai_depoyment_name: OpenAI deployment 이름 (예: gpt-4o)\n",
    "3. openai_api_version: OpenAI API 버전 (예: 2024-02-01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import json\n",
    "\n",
    "runs = 10\n",
    "sleep_time_ms = 0\n",
    "url = \"https://apim-jl-nov26.azure-api.net/openai-lb/deployments/gpt-4o/chat/completions?api-version=2024-02-01\"\n",
    "api_runs = []\n",
    "apim_subscription_key = \"33c8bd9d306b4119aca42d37d5cba0b5\"\n",
    "\n",
    "for i in range(runs):\n",
    "    print(\"▶️ Run:\", i+1, \"/\", runs)\n",
    "    \n",
    "\n",
    "    messages={\"messages\":[\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic unhelpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "    ]}\n",
    "    \n",
    "    start_time = time.time()\n",
    "    response = requests.post(url, headers = {'Ocp-Apim-Subscription-Key':apim_subscription_key}, json = messages)\n",
    "    response_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"⌚ {response_time:.2f} seconds\")\n",
    "    # Check the response status code and apply formatting\n",
    "    if 200 <= response.status_code < 300:\n",
    "        status_code_str = '\\x1b[1;32m' + str(response.status_code) + \" - \" + response.reason + '\\x1b[0m'  # Bold and green\n",
    "    elif response.status_code >= 400:\n",
    "        status_code_str = '\\x1b[1;31m' + str(response.status_code) + \" - \" + response.reason + '\\x1b[0m'  # Bold and red\n",
    "    else:\n",
    "        status_code_str = str(response.status_code)  # No formatting\n",
    "\n",
    "    # Print the response status with the appropriate formatting\n",
    "    print(\"Response status:\", status_code_str)\n",
    "    \n",
    "    print(\"Response headers:\", response.headers)\n",
    "    \n",
    "    if \"x-ms-region\" in response.headers:\n",
    "        print(\"x-ms-region:\", '\\x1b[1;31m'+response.headers.get(\"x-ms-region\")+'\\x1b[0m') # this header is useful to determine the region of the backend that served the request\n",
    "        api_runs.append((response_time, response.headers.get(\"x-ms-region\")))\n",
    "    \n",
    "    if (response.status_code == 200):\n",
    "        data = json.loads(response.text)\n",
    "        print(\"Token usage:\", data.get(\"usage\"), \"\\n\")\n",
    "        print(\"💬 \", data.get(\"choices\")[0].get(\"message\").get(\"content\"), \"\\n\")\n",
    "    else:\n",
    "        print(response.text)   \n",
    "\n",
    "    time.sleep(sleep_time_ms/1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plot'></a>\n",
    "### 🔍 Load Balancing 결과 분석\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = [15, 7]\n",
    "df = pd.DataFrame(api_runs, columns=['Response Time', 'Region'])\n",
    "df['Run'] = range(1, len(df) + 1)\n",
    "\n",
    "# Define a color map for each region\n",
    "color_map = {'West US': 'lightpink', 'East US': 'lightblue'}  # Add more regions and colors as needed\n",
    "\n",
    "# Plot the dataframe with colored bars\n",
    "ax = df.plot(kind='bar', x='Run', y='Response Time', color=[color_map.get(region, 'gray') for region in df['Region']], legend=False)\n",
    "\n",
    "# Add legend\n",
    "legend_labels = [plt.Rectangle((0, 0), 1, 1, color=color_map.get(region, 'gray')) for region in df['Region'].unique()]\n",
    "ax.legend(legend_labels, df['Region'].unique())\n",
    "\n",
    "plt.title('Load Balancing results')\n",
    "plt.xlabel('Runs')\n",
    "plt.ylabel('Response Time')\n",
    "plt.xticks(df['Run'], rotation=0)\n",
    "\n",
    "average = df['Response Time'].mean()\n",
    "plt.axhline(y=average, color='r', linestyle='--', label=f'Average: {average:.2f}')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
